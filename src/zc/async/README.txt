========
zc.async
========

The zc.async package provides a way to make asynchronous application
calls.

Calls are handled by worker processes, each of which is typically a
standard Zope process, identified by a UUID [#uuid]_, that
may simultaneously perform other tasks (such as handle standard web
requests).  Each worker is responsible for claiming and performing calls
in its main thread or additional threads.  To have multiple workers on
the same queue of tasks, share the database with ZEO.

Pending calls and worker data objects are stored in a data manager
object in the ZODB.  This is typically stored in the root of the ZODB,
alongside the application object, with a key of 'zc.async.datamanager',
but the adapter that obtains the data manager can be replaced to point
to a different location.

Worker data objects have queues representing potential or current tasks
for the worker, in the main thread or a secondary thread.  Each worker
has a virtual loop, part of the Twisted or asyncore main loop, for every
worker process, which is responsible for responding to system calls
(like pings) and for claiming pending main thread calls by moving them
from the datamanager async queue to their own.  Each worker thread queue
also represents spots for claiming and performing pending thread
calls.

Set Up
======

By default, zc.async expects to have an object in the root of
the ZODB, alongside the application object, with a key of
'zc.async.datamanager'.  The package includes subscribers to
zope.app.appsetup.interfaces.IDatabaseOpenedEvent that sets an instance
up in this location if one does not exist.

One version of the subscriber expects to put the object in the same
database as the main application (`basicInstallerAndNotifier`), and the
other version expects to put the object in a secondary database, with a
reference to it in the main database (`installerAndNotifier`).  The
second approach keeps the database churn generated by zc.async, which
can be significant, separate from your main data.  You can use either
(or your own); the first version is the default, since it requires no
additional set-up. When this documentation is run as a test, it is run
twice, once with each setup.  To accomodate this, in our example below
we appear to pull the "installerAndNotifier" out of the air: it is
installed as a global when the test is run.  You will want to use one of
the two subscribers mentioned above, or roll your own.

XXX explain possible gotchas if you run the separate database (i.e., you may
have to explicitly add objects to connections if you create an object for the
main database and put it as a partial callable or argument in the same
transaction).

Let's assume we have a reference to a database named `db`, a connection
named `conn`, a `root`, and an application in the 'app' key
[#setup]_.  If we provide a handler, fire the event and examine the
root, we will see the new datamanager.

    >>> import zope.component
    >>> import zc.async.subscribers
    >>> zope.component.provideHandler(installerAndNotifier) # see above
    ... # for explanation of where installerAndNotifier came from
    >>> import zope.event
    >>> import zope.app.appsetup.interfaces
    >>> zope.event.notify(zope.app.appsetup.interfaces.DatabaseOpened(db))
    >>> import transaction
    >>> t = transaction.begin()
    >>> root['zc.async.datamanager'] # doctest: +ELLIPSIS
    <zc.async.datamanager.DataManager object at ...>

The default adapter from persistent object to datamanager will get us
the same result.

    >>> import zc.async.adapters
    >>> zope.component.provideAdapter(
    ...     zc.async.adapters.defaultDataManagerAdapter)
    >>> import zc.async.interfaces
    >>> zc.async.interfaces.IDataManager(app) # doctest: +ELLIPSIS
    <zc.async.datamanager.DataManager object at ...>

Normally, each process discovers or creates its UUID and registers
itself with the data manager as a worker.  This would have happened when
the data manager was announced as available in the InstallerAndNotifier
above.

    >>> from zope.component import eventtesting
    >>> evs = eventtesting.getEvents(
    ...     zc.async.interfaces.IDataManagerAvailableEvent)
    >>> evs # doctest: +ELLIPSIS
    [<zc.async.interfaces.DataManagerAvailable object at ...>]

So now we would have had a subscriber that installed the worker in the
data manager.  But right now there are no workers, just because we
didn't want to talk about the next step yet.

    >>> len(zc.async.interfaces.IDataManager(app).workers)
    0

Let's install the subscriber we need and refire the event.  Our worker
will have a UUID created for it, and then it will be installed with the
UUID as key.  We can't actually use the same event because it has an
object from a different connection, so we'll recreate it.

    >>> zope.component.provideHandler(
    ...     zc.async.subscribers.installTwistedEngine)
    >>> zope.event.notify(
    ...     zc.async.interfaces.DataManagerAvailable(
    ...         root['zc.async.datamanager']))
    >>> time_passes()
    True
    >>> t = transaction.begin() # sync
    >>> len(zc.async.interfaces.IDataManager(app).workers)
    1
    >>> zc.async.interfaces.IDataManager(app).workers.values()[0]
    ... # doctest: +ELLIPSIS
    <zc.async.datamanager.Worker object at ...>
    >>> (zc.async.interfaces.IDataManager(app).workers.values()[0].engineUUID
    ...  is not None)
    True

The new UUID, in hex, is stored in INSTANCE_HOME/etc/uuid.txt

    >>> import uuid
    >>> import os
    >>> f = open(os.path.join(
    ...     os.environ.get("INSTANCE_HOME"), 'etc', 'uuid.txt'))
    >>> uuid_hex = f.readline().strip()
    >>> f.close()
    >>> uuid = uuid.UUID(uuid_hex)
    >>> worker = zc.async.interfaces.IDataManager(app).workers[uuid]
    >>> worker.UUID == uuid
    True

The file is intended to stay in the instance home as a persistent identifier
of this particular worker.

Our worker has `thread` and `reactor` jobs, with all jobs available.

    >>> worker.thread.size
    1
    >>> worker.reactor.size
    4
    >>> len(worker.thread)
    0
    >>> len(worker.reactor)
    0

We now have a simple set up: a data manager with a single worker.  Let's start
making some asynchronous calls!

Basic Usage: IManager.add
=========================

The simplest case is simple to perform: pass a persistable callable to the
manager's .add method.

    >>> from zc.async import interfaces
    >>> dm = zc.async.interfaces.IDataManager(app)
    >>> def send_message():
    ...     print "imagine this sent a message to another machine"
    >>> partial = dm.reactor.put(send_message)
    >>> transaction.commit()

Now a few cycles need to pass in order to have the job performed.  We'll
use a helper function called `time_flies` to simulate the asynchronous
cycles necessary for the manager and workers to perform the task.

    >>> count = time_flies(dm.workers.values()[0].poll_seconds)
    imagine this sent a message to another machine

You can also pass a datetime.datetime to schedule the call: the
safest thing to use is a UTC timezone. The datetime is interpreted as a
UTC datetime.

    >>> t = transaction.begin()
    >>> import datetime
    >>> import pytz
    >>> datetime.datetime.now(pytz.UTC)
    datetime.datetime(2006, 8, 10, 15, 44, 27, 211, tzinfo=<UTC>)
    >>> partial = dm.reactor.put(
    ...     send_message, datetime.datetime(
    ...         2006, 8, 10, 15, 45, tzinfo=pytz.UTC))
    >>> partial.begin_after
    datetime.datetime(2006, 8, 10, 15, 45, tzinfo=<UTC>)
    >>> transaction.commit()
    >>> count = time_flies(10)
    >>> count = time_flies(10)
    >>> count = time_flies(10)
    >>> count = time_flies(5)
    imagine this sent a message to another machine
    >>> datetime.datetime.now(pytz.UTC)
    datetime.datetime(2006, 8, 10, 15, 45, 2, 211, tzinfo=<UTC>)

If you set a time that has already passed, it will be run as if it had
been set to run immediately.

    >>> t = transaction.begin()
    >>> partial = dm.reactor.put(
    ...     send_message, datetime.datetime(2006, 7, 21, 12, tzinfo=pytz.UTC))
    >>> transaction.commit()
    >>> count = time_flies(5)
    imagine this sent a message to another machine

The `add` method of the thread and reactor queues is the manager's
entire application API.  Other methods are used to introspect, but are
not needed for basic usage.  We will examine the introspection API below
(`Manager Introspection`_), and will discuss an advanced feature of the
`add` method (`Specifying Workers`), but let's explore some more usage
patterns first.

Typical Usage: zc.async.Partial
================================

...(currently tests and discussion are in partial.txt and datamanager.txt.
We need user-friendly docs, as well as stress tests.  The remainder of the
below is somewhat unedited and incomplete at the moment)...

    >>> t = transaction.begin()
    >>> import zc.async
    >>> import persistent
    >>> import transaction
    >>> import zc.async.partial
    >>> class Demo(persistent.Persistent):
    ...     counter = 0
    ...     def increase(self, value=1):
    ...         self.counter += value
    ...
    >>> app['demo'] = Demo()
    >>> transaction.commit() # XXX example of gotcha for multiple databases:
    ... # connection.add or commit before adding to partial
    >>> app['demo'].counter
    0
    >>> partial = dm.reactor.put(
    ...     zc.async.partial.Partial(app['demo'].increase))
    >>> transaction.commit()
    >>> count = time_flies(5)

We need to commit the transaction in our connection so that we get the
changes in other connections (beginning and committing transactions sync
connections).

    >>> app['demo'].counter
    0
    >>> t = transaction.begin()
    >>> app['demo'].counter
    1

The deferred class can take arguments and keyword arguments for the
wrapped callable as well, similar to Python 2.5's `partial`.  For this
use case, though, realize that the partial will be called with no
arguments, so you must supply all necessary arguments for the callable
on creation time.

    >>> partial = dm.reactor.put(
    ...     zc.async.partial.Partial(app['demo'].increase, 5))
    >>> transaction.commit()
    >>> count = time_flies(5)
    >>> t = transaction.begin()
    >>> app['demo'].counter
    6
    >>> partial = dm.reactor.put(
    ...     zc.async.partial.Partial(app['demo'].increase, value=10))
    >>> transaction.commit()
    >>> count = time_flies(5)
    >>> t = transaction.begin()
    >>> app['demo'].counter
    16

Optimized Usage
===============

Writing a task that doesn't need a ZODB connection
--------------------------------------------------

...Twisted reactor tasks are best for this...

...also could have different IPartial implementation sets self as
ACTIVE, commits and closes connection, calls f with args, and when
result returns, gets connection again and sets value on it, changes
state, and performs callbacks, sets state...

Multiple ZEO workers
--------------------

...

Catching and Fixing Errors
==========================

...call installed during InstallTwistedWorker to check on worker...

...worker finds another process already installed with same UUID; could be
shutdown error (ghost of self) or really another process...show engineUUID...
some discussion already in datamanager.txt...

Gotchas
=======

...some callbacks may still be working when partial is completed.  Therefore
partial put in `completed` for worker so that it can have a chance to run to
completion (in addition to other goals, like being able to look at 

Patterns
========

Partials That Need a Certain Environment
----------------------------------------

...Partial that needs a certain environment: wrap partial in partial.  Outer
partial is responsible for checking if environment is good; if so, run inner
partial, and if not, create a new outer partial, copy over our excluded worker
UUIDs, add this worker UUID, set perform_after to adjusted value,
and schedule it...

Callbacks That Want to be Performed by a Worker
-----------------------------------------------

Callbacks are called immediately, whether they be within the call to the
partial, or within the `addCallbacks` call.  If you want the job to be done
asynchronously, make the callback with a partial.  The partial will get
a reference to the data_manager used by the main partial.  It can create a
partial, assign it to one of the data manager queues, and return the partial.
Consider the following.

    >>> def multiply(*args):
    ...     res = 1
    ...     for a in args:
    ...         res *= a
    ...     return res
    ...
    >>> def doCallbackWithPartial(partial, res):
    ...     p = zc.async.partial.Partial(multiply, 2, res)
    ...     zc.async.interfaces.IDataManager(partial).thread.put(p)
    ...     return p
    ...
    >>> p = dm.thread.put(zc.async.partial.Partial(multiply, 3, 4))
    >>> p_callback = p.addCallbacks(
    ...     zc.async.partial.Partial.bind(doCallbackWithPartial))
    >>> transaction.commit()
    >>> import time
    >>> for i in range(100):
    ...     ignore = time_flies(5)
    ...     time.sleep(0)
    ...     t = transaction.begin()
    ...     if p_callback.state == zc.async.interfaces.COMPLETED:
    ...         break
    ...
    >>> p.result
    12
    >>> p.state == zc.async.interfaces.COMPLETED
    True
    >>> p_callback.state == zc.async.interfaces.COMPLETED
    True
    >>> p_callback.result
    24

Progress Reports
----------------

Using zc.twist.Partial, or by managing your own connections
otherwise, you can send messages back during a long-running connection. 
For instance, imagine you wanted to annotate a partial with progress
messages, while not actually committing the main work.

Here's an example of one way of getting this to work.  We can use the partial's
annotations, which are not touched by the partial code and are a separate
persistent object, so can be changed concurrently without conflict errors.

We'll run the partial within a threaded worker. The callable could use
twisted.internet.reactor.callFromThread to get the change to be made. 
Parts of the twist.Partial machinery expect to be called in the main
thread, where the twisted reactor is running.

    >>> import twisted.internet.reactor
    >>> def setAnnotation(partial, annotation_key, value):
    ...     partial.annotations[annotation_key] = value
    ...
    >>> import threading
    >>> thread_lock = threading.Lock()
    >>> main_lock = threading.Lock()
    >>> acquired = thread_lock.acquire()
    >>> acquired = main_lock.acquire()
    >>> def callWithProgressReport(partial):
    ...     print "do some work"
    ...     print "more work"
    ...     print "about half done"
    ...     twisted.internet.reactor.callFromThread(zc.twist.Partial(
    ...         setAnnotation, partial, 'zc.async.partial_txt.half_done', True))
    ...     main_lock.release()
    ...     acquired = thread_lock.acquire()
    ...     return 42
    ...
    >>> p = dm.thread.put(zc.async.partial.Partial.bind(callWithProgressReport))
    >>> transaction.commit()
    >>> ignore = time_flies(5) # get the reactor to kick for main call
    do some work
    more work
    about half done
    >>> ignore = time_flies(5) # get the reactor to kick for progress report
    >>> acquired = main_lock.acquire()
    >>> t = transaction.begin() # sync
    >>> p.annotations.get('zc.async.partial_txt.half_done')
    True
    >>> p.state == zc.async.interfaces.ACTIVE
    True
    >>> thread_lock.release()
    >>> for i in range(100):
    ...     ignore = time_flies(5)
    ...     time.sleep(0)
    ...     t = transaction.begin()
    ...     if p.state == zc.async.interfaces.COMPLETED:
    ...         break
    ...
    >>> p.result
    42
    >>> thread_lock.release()
    >>> main_lock.release()

Expiration
----------

If you want your call to expire after a certain amount of time, keep
track of time yourself, and return a failure if you go over.  The
partial does not offer special support for this use case.

Stopping the Engine
-------------------

The subscriber that sets up the async engine within the Twisted reactor also
sets up a tearDown trigger.  We can look in our faux reactor and get it.

    >>> len(faux.triggers)
    1
    >>> len(faux.triggers[0])
    3
    >>> faux.triggers[0][:2]
    ('before', 'shutdown')
    >>> dm.workers.values()[0].engineUUID is not None
    True
    >>> d = faux.triggers[0][2]()
    >>> t = transaction.begin()
    >>> dm.workers.values()[0].engineUUID is None
    True

[#tear_down]_

=========
Footnotes
=========

.. [#uuid] UUIDs are generated by http://zesty.ca/python/uuid.html, as
    incorporated in Python 2.5.  They are expected to be found in 
    os.path.join(os.environ.get("INSTANCE_HOME"), 'etc', 'uuid.txt');
    this file will be created and populated with a new UUID if it does
    not exist.

.. [#setup] This is a bit more than standard set-up code for a ZODB test,
    because it sets up a multi-database.

    >>> from ZODB.tests.util import DB # use conflict resolution test one XXX
    >>> class Factory(object):
    ...     def __init__(self, name):
    ...         self.name = name
    ...     def open(self):
    ...         return DB()
    ...
    >>> import zope.app.appsetup.appsetup
    >>> db = zope.app.appsetup.appsetup.multi_database(
    ...     (Factory('main'), Factory('zc.async')))[0][0]
    >>> conn = db.open()
    >>> root = conn.root()
    >>> import zope.app.folder # import rootFolder
    >>> app = root['Application'] = zope.app.folder.rootFolder()
    >>> import transaction
    >>> transaction.commit()

    You must have two adapter registrations: IConnection to
    ITransactionManager, and IPersistent to IConnection.  We will also
    register IPersistent to ITransactionManager because the adapter is
    designed for it.

    >>> from zc.twist import transactionManager, connection
    >>> import zope.component
    >>> zope.component.provideAdapter(transactionManager)
    >>> zope.component.provideAdapter(connection)
    >>> import ZODB.interfaces
    >>> zope.component.provideAdapter(
    ...     transactionManager, adapts=(ZODB.interfaces.IConnection,))

    We need to be able to get data manager partials for functions and methods;
    normal partials for functions and methods; and a data manager for a partial.
    Here are the necessary registrations.

    >>> import zope.component
    >>> import types
    >>> import zc.async.interfaces
    >>> import zc.async.partial
    >>> import zc.async.adapters
    >>> zope.component.provideAdapter(
    ...     zc.async.adapters.method_to_datamanagerpartial)
    >>> zope.component.provideAdapter(
    ...     zc.async.adapters.function_to_datamanagerpartial)
    >>> zope.component.provideAdapter( # partial -> datamanagerpartial
    ...     zc.async.adapters.DataManagerPartial,
    ...     provides=zc.async.interfaces.IDataManagerPartial)
    >>> zope.component.provideAdapter(
    ...     zc.async.adapters.partial_to_datamanager)
    >>> zope.component.provideAdapter(
    ...     zc.async.partial.Partial,
    ...     adapts=(types.FunctionType,),
    ...     provides=zc.async.interfaces.IPartial)
    >>> zope.component.provideAdapter(
    ...     zc.async.partial.Partial,
    ...     adapts=(types.MethodType,),
    ...     provides=zc.async.interfaces.IPartial)
    ...
    
    A monkeypatch, removed in another footnote below.

    >>> import datetime
    >>> import pytz
    >>> old_datetime = datetime.datetime
    >>> def set_now(dt):
    ...     global _now
    ...     _now = _datetime(*dt.__reduce__()[1])
    ...
    >>> class _datetime(old_datetime):
    ...     @classmethod
    ...     def now(klass, tzinfo=None):
    ...         if tzinfo is None:
    ...             return _now.replace(tzinfo=None)
    ...         else:
    ...             return _now.astimezone(tzinfo)
    ...     def astimezone(self, tzinfo):
    ...         return _datetime(
    ...             *super(_datetime,self).astimezone(tzinfo).__reduce__()[1])
    ...     def replace(self, *args, **kwargs):
    ...         return _datetime(
    ...             *super(_datetime,self).replace(
    ...                 *args, **kwargs).__reduce__()[1])
    ...     def __repr__(self):
    ...         raw = super(_datetime, self).__repr__()
    ...         return "datetime.datetime%s" % (
    ...             raw[raw.index('('):],)
    ...     def __reduce__(self):
    ...         return (argh, super(_datetime, self).__reduce__()[1])
    >>> def argh(*args, **kwargs):
    ...     return _datetime(*args, **kwargs)
    ...
    >>> datetime.datetime = _datetime
    >>> _start = _now = datetime.datetime(
    ...     2006, 8, 10, 15, 44, 22, 211, pytz.UTC)

    We monkeypatch twisted.internet.reactor (and replace it below).  

    >>> import twisted.internet.reactor
    >>> import threading
    >>> import bisect
    >>> class FauxReactor(object):
    ...     def __init__(self):
    ...         self.time = 0
    ...         self.calls = []
    ...         self.triggers = []
    ...         self._lock = threading.Lock()
    ...     def callLater(self, delay, callable, *args, **kw):
    ...         res = (delay + self.time, callable, args, kw)
    ...         self._lock.acquire()
    ...         bisect.insort(self.calls, res)
    ...         self._lock.release()
    ...         # normally we're supposed to return something but not needed
    ...     def callFromThread(self, callable, *args, **kw):
    ...         self._lock.acquire()
    ...         bisect.insort(
    ...             self.calls,
    ...             (self.time, callable, args, kw))
    ...         self._lock.release()
    ...     def addSystemEventTrigger(self, *args):
    ...         self.triggers.append(args) # 'before', 'shutdown', callable
    ...     def time_flies(self, time):
    ...         global _now
    ...         end = self.time + time
    ...         ct = 0
    ...         while self.calls and self.calls[0][0] <= end:
    ...             self.time, callable, args, kw = self.calls.pop(0)
    ...             _now = _datetime(
    ...                 *(_start + datetime.timedelta(
    ...                     seconds=self.time)).__reduce__()[1])
    ...             callable(*args, **kw) # normally this would get try...except
    ...             ct += 1
    ...         self.time = end
    ...         return ct
    ...     def time_passes(self):
    ...         if self.calls and self.calls[0][0] <= self.time:
    ...             self.time, callable, args, kw = self.calls.pop(0)
    ...             callable(*args, **kw)
    ...             return True
    ...         return False
    ...
    >>> faux = FauxReactor()
    >>> oldCallLater = twisted.internet.reactor.callLater
    >>> oldCallFromThread = twisted.internet.reactor.callFromThread
    >>> oldAddSystemEventTrigger = (
    ...     twisted.internet.reactor.addSystemEventTrigger)
    >>> twisted.internet.reactor.callLater = faux.callLater
    >>> twisted.internet.reactor.callFromThread = faux.callFromThread
    >>> twisted.internet.reactor.addSystemEventTrigger = (
    ...     faux.addSystemEventTrigger)
    >>> time_flies = faux.time_flies
    >>> time_passes = faux.time_passes

.. [#tear_down]

    >>> twisted.internet.reactor.callLater = oldCallLater
    >>> twisted.internet.reactor.callFromThread = oldCallFromThread
    >>> twisted.internet.reactor.addSystemEventTrigger = (
    ...     oldAddSystemEventTrigger)
    >>> datetime.datetime = old_datetime
