
==============================
Quickstart with ``virtualenv``
==============================

Prerequisites
=============

------------
Installation
------------

To start, install |virtualenv|_ and create a virtual environment for our
experiments.

.. sidebar:: ``virtualenv`` and ``zc.buildout``

   I prefer |zc.buildout|_ for production deployments, but |virtualenv|_ is
   very nice for quick experimentation.  Another quick-start uses
   |zc.buildout|_.

::

    $ easy_install virtualenv
    $ virtualenv quickstart

Install |async|_ in the virtual environment.

::

    $ cd quickstart/
    $ ./bin/easy_install zc.async

.. |zc.buildout| replace:: ``zc.buildout``

.. _`zc.buildout`: http://pypi.python.org/pypi/zc.buildout

.. |virtualenv| replace:: ``virtualenv``

.. _virtualenv: http://pypi.python.org/pypi/virtualenv

.. |async| replace:: ``zc.async``

.. _`async`: http://pypi.python.org/pypi/zc.async

------------
Dependencies
------------

.. sidebar:: Example Dependencies

   Here's an example listing of the site-packages brought in by a run of this
   quick-start.
   
   ::
   
       $ ls lib/python2.5/site-packages/
       Twisted-8.1.0-py2.5-macosx-10.5-i386.egg
       ZConfig-2.5.1-py2.5.egg
       ZODB3-3.8.1b5-py2.5-macosx-10.5-i386.egg
       easy-install.pth
       pytz-2008c-py2.5.egg
       rwproperty-1.0-py2.5.egg
       setuptools-0.6c8-py2.5.egg
       setuptools.pth
       uuid-1.30-py2.5.egg
       zc.async-1.4.0-py2.5.egg
       zc.dict-1.2.1-py2.5.egg
       zc.queue-1.1-py2.5.egg
       zc.twist-1.3-py2.5-macosx-10.5-i386.egg
       zdaemon-2.0.2-py2.5.egg
       zope.bforest-1.2-py2.5.egg
       zope.component-3.4.0-py2.5.egg
       zope.deferredimport-3.4.0-py2.5.egg
       zope.deprecation-3.4.0-py2.5.egg
       zope.event-3.4.0-py2.5.egg
       zope.i18nmessageid-3.4.3-py2.5-macosx-10.5-i386.egg
       zope.interface-3.4.1-py2.5-macosx-10.5-i386.egg
       zope.minmax-1.1.0-py2.5.egg
       zope.proxy-3.4.1-py2.5-macosx-10.5-i386.egg
       zope.testing-3.6.0-py2.5.egg

This installed several packages.

- the ZODB_, an object database from the Zope project;

- Twisted_, a framework for networked applications;

- the component architecture from the Zope project;

- and a few smaller packages.

All of these, and zc.async, are distributed under BSD-like licenses such as
LGPL and ZPL_.

.. _ZODB: http://pypi.python.org/pypi/ZODB3

.. _Twisted: http://pypi.python.org/pypi/Twisted

.. _ZPL: http://en.wikipedia.org/wiki/Zope_Public_License

----------
ZEO Server
----------

zc.async relies on a distributed ZODB technology called ZEO ("Zope Enterprise
Objects") to distribute work. ZEO has a central database server to which client
processes connect.

Let's start the ZEO Server::

    $ ./bin/runzeo -a 9999 -f test.fs &

That starts a database server, accessible on port 9999 of your local machine,
saving the data in the test.fs file.


Starting |async|
================

--------
A Client
--------

Now let's start a Python with a client connection to the database server.

Start up ``bin/python`` (not your system python, but the one in virtualenv's
``quickstart/bin``)::

    $ ./bin/python

This will be our single client process.

You might have many, each connecting to the main database server, and each able
to perform and/or request |async| jobs.

-------------------
Database Connection
-------------------

Connect to the database.

::

    >>  import ZEO.ClientStorage
    >>  import ZODB
    >>  storage = ZEO.ClientStorage.ClientStorage(
    ...     ('127.0.0.1', 9999))
    >>  db = ZODB.DB(storage)

.. When run as a doctest, this uses a simple FileStorage, rather than a
   ClientStorage.

    >>> import ZODB.FileStorage
    >>> storage = ZODB.FileStorage.FileStorage(
    ...     'zc_async.fs', create=True)
    >>> from ZODB.DB import DB
    >>> db = DB(storage)

-------------
Start |async|
-------------

Basics
------

Now we do some basic configuration.  This first bit installs some default
adapters.  You might not ever have to worry too much about them.

    >>> import zc.async.configure
    >>> zc.async.configure.base()

Policy
------

This second part is policy, and if you ever put zc.async in production, you'll
want to understand what's going on here.  We'll talk about what's going on here
a little later.

    >>> zc.async.configure.start(
    ...     db, poll_interval=1)

Now the system has a ``dispatcher`` polling for jobs every second.

Using |async|
=============

---------
The Queue
---------

The ``start`` function also installed a queue.  To get zc.async to do work, you
put a job in a queue, and commit the transaction.

First, let's get the queue that we have installed.  We need to open a
connection to the database.  Then we get the queue.

    >>> conn = db.open()
    >>> import zc.async.interfaces
    >>> q = zc.async.interfaces.IQueue(conn)

-----
A Job
-----

.. sidebar:: A Silly Example

    This is a silly example. Imagine instead that this was some really
    long-running job. Maybe you have lots of these jobs coming in, and you need
    to have many machines to claim jobs and perform them, so that you can
    scale. Maybe this job divides itself up into parallel or serial jobs, and
    this parent job isn't done until all the children jobs run to completion.

    Or maybe this is a silly example.
..

Let's put a job in our queue.  This silly example will return the current time.

    >>> import time
    >>> j = q.put(time.time)

It's not done yet.

    >>> j.result
    >>> j.status
    u'pending-status'

-------------
A Transaction
-------------

We have to commit the transaction for the dispatcher to see the job.

    >>> import transaction
    >>> transaction.commit()

--------
A Result
--------

Now wait a second and then try this.  "transaction.begin" will sync up our
database with database changes made elsewhere.

.. This lets us "wait a second".

    >>> import zc.async.testing
    >>> res = zc.async.testing.wait_for_result(j)

..

    >>> _ = transaction.begin()
    >>> j.result
    1216179006.856108
    >>> j.status
    u'completed-status'

-----------
Another Job
-----------

You can also make closures by passing in the job class explicitly.  Generating
RSA keys is actually a reasonable real-world use case for something like this.

::

    >>  import subprocess
    >>  j = q.put(zc.async.job.Job(
    ...     subprocess.call,
    ...     ['openssl', 'genrsa', '-out',
    ...      'key.pem', '1024']))
    >>  transaction.commit()

We need to begin the transaction to see the result--which in this case is
simply ``0``, indicating a successful UNIX process.

::

    >>  j.result
    >>  _ = transaction.begin()
    >>  j.result
    0

We can open the file to show the result.

::

    >>  subprocess.call(['cat', 'key.pem'])
    -----BEGIN RSA PRIVATE KEY-----
    MIICXgIBAAKBgQCYAZW+HjDGJhRHnUlZZWqhrGOxU2K/RhssmcMs0JLnWI2cWmZ+
    ...
    CEcz6ZbO8zm4AEGI/dqLicZh3bhunhflAovW6WxbNKLENQ==
    -----END RSA PRIVATE KEY-----
    0

Running Your Own Code
=====================

------------------------
A Monte Carlo Simulation
------------------------

.. sidebar:: Another Silly Example

   Monte Carlo simulations are generally better suited to other tasks in
   real-world use; pi is typically calculated by `far more sophisticated
   means`_.

We've now seen some simple examples from the standard library.  But how do you
get your own work done?

Let's say we want to write an approach a chestnut of a problem: use a `Monte
Carlo simulation`_ (read "throwing darts and analyzing the results") to
`calculate pi`_.  This will use |async| much like the map-reduce approach
of `Hadoop`_: we will want to distribute the work of running the simulation to
multiple machines so the result can be done faster.

.. note::

   The ``zc.buildout`` quick-start instead uses |async| to generate PDFs
   on the fly, if you'd like a different usage example.

.. _`Monte Carlo simulation`: http://en.wikipedia.org/wiki/Monte_Carlo_method

.. _`Hadoop`: http://hadoop.apache.org/core/

.. _`calculate pi`: http://math.fullerton.edu/mathews/n2003/MonteCarloPiMod.html

.. _`far more sophisticated means`: http://en.wikipedia.org/wiki/Computing_Ï€

---------------------------------
Picklable Callables and Arguments
---------------------------------

You want a job to have a reference to your own callable, so the job will get
the work you define performed.

This reference, of the job to your callable, will need to be persisted in the
database.

.. sidebar:: ZODB Persistence Rules
   
   We don't need these now.  But if you are really curious about ZODB
   persistence rules, here's a start.
   
   - Anything pickleable can be persisted.  Module global functions can be
     pickled (by name), for instance, and will come in handy for our examples.
   
   - Custom classes should typically inherit from persistent.Persistent.
     Instances of persistent.Persistent subclasses are each stored as a single
     record in the database, and references to them are handled efficiently.
   
   - Subclasses of persistent.Persistent produce instances that recognize when
     their *direct* attributes have been written, and inform the database that
     they are dirty, for the next committed transaction.  Standard,
     non-persistent-aware mutables such as lists, sets and dicts do *not* know
     when they have been changed, and are best avoided, or at least not
     mutated. A variety of persistent-aware replacements for these types are
     available.
   
   - Use the transaction module to commit and abort transactions in the ZODB.
   
   More advanced concerns include the following.
   
   - An optimistic implementation of MVCC_ in the ZODB means that you should be
     careful reading (not writing) one persistent.Persistent instance (record)
     and writing another persistent.Persistent instance with a value that
     depends on the first, read value within a transaction.
   
   - Concurrent transactions can produce write conflict errors.  Transactions
     are often automatically retried in |async| and other ZODB-based systems if
     conflict errors are encountered.  If this is not desired for a given
     |async| job, it should be given a ``zc.async.job.NeverRetry`` retry
     policy, as discussed elsewhere in this documentation.
   
   For ZODB documentation see http://www.zope.org/Wikis/ZODB/guide/zodb.html

Because zc.async uses the ZODB for its persistence mechanism, the ZODB's
persistence rules are in effect.

Luckily, these are fairly simple.

For now, we'll stay as simple as it gets: if you use *module global functions*
and *immutables*, and share software across instances, you'll be fine.

ZODB allows a lot more, if you're willing to follow a few more rules, but that
one rule will get us moving for this quick-start.

.. _MVCC: http://en.wikipedia.org/wiki/Multiversion_concurrency_control

-------------
Process UUIDs
-------------

Exit the Python interpreter (control-D).  Look around in the directory
(``ls``): you should see a few database files, the key.pem you created, and a
new file: ``uuid.txt``.  It should look something like this::

    $ cat uuid.txt
    afd1e0d0-52e1-11dd-879b-0017f2c49bdd
    ------------------------------------------------------------------------
    The value above (and this file) is created and used by the zc.async
    package. It is intended to uniquely identify this software instance when
    it is used to start a zc.async dispatcher.  This allows multiple
    dispatchers, each in its own software instance, to connect to a single
    database to do work.
    
    In order to decide where to look for this file (or to create it, if
    necessary), the module looks in ``os.environ['ZC_ASYNC_UUID']`` for a
    file name.
    
    If you are using zdaemon (http://pypi.python.org/pypi/zdaemon) to
    daemonize your process, you can set this in a zdaemon environment section
    of your zdaemon.conf. Supervisor (http://supervisord.org/) also provides
    this functionality. Other similar tools probably do as well.
    
    If the ``ZC_ASYNC_UUID`` is not found in the environment, it will use
    ``os.path.join(os.getgwd(), 'uuid.txt')`` as the file name.
    
    To get a new identifier for this software instance, delete this file,
    restart Python, and import zc.async.instanceuuid.  This file will be
    recreated with a new value.

That text is intended to be self-explanatory, so hopefully it made sense to
you.  We'll handle these UUIDs more explicitly in a moment.

-----------
Make a File
-----------

Make a new Python file.  Let's call it ``pi.py``.
Save this file in ``lib/python2.5/site-packages/``.

Use the following for the file content.

.. sidebar:: Code Walkthrough

    This code walkthrough focuses on the elements needed to use |async|,
    rather than the calculation of pi.  Numerous explanations of this Monte
    Carlo simulation to calculate pi are on the internet.  I liked `this one`_.

    We begin with some imports.

    The ``generate_sample`` code will be run on multiple processes to produce
    samples for our Monte Carlo function simulation.  It is ignorant of
    |async|.
    
    Once the samples are all done, we'll reduce the results with
    ``process_samples``.  It will return an approximation of pi, with accuracy
    determined by the total size of the aggregated samples, assuming even
    distribution of the random numbers.  As you'll see soon, we'll be using a
    |async| convenience function for parallel jobs that gives all of the
    completed jobs that have been running in parallel to this, the
    postprocessing call. Therefore, ``process_samples`` gets the ``result`` of
    ``generate_sample`` off of each job. Other than that, this function is
    ignorant of |async|.
    
    The last code block should look similar to our previous example of starting
    up a dispatcher, except this one uses the main, installed Twisted reactor,
    rather than a threaded instance.  It creates the database, configures
    zc.async, and starts the reactor.

::

    import random
    import math

    import ZEO.ClientStorage
    import ZODB
    import twisted.internet.reactor

    import zc.async.configure

    def generate_sample(size=100000):
        count = 0
        for i in range(size):
            if math.hypot(random.random(), random.random()) < 1:
                count += 1
        return count, size

    def process_samples(*sample_jobs):
        count = 0 
        size = 0
        for j in sample_jobs:
            count += j.result[0]
            size += j.result[1]
        return 4.0 * count / size

    if __name__ == '__main__':
        storage = ZEO.ClientStorage.ClientStorage(
            ('127.0.0.1', 9999))
        db = ZODB.DB(storage)
        zc.async.configure.base()
        zc.async.configure.start(
            db, poll_interval=1, twisted=True)
        twisted.internet.reactor.run()

.. We'll need these defined when we run this as a test.

    >>> import random
    >>> import math

    >>> def generate_sample(size=100000):
    ...     count = 0
    ...     for i in range(size):
    ...         if math.hypot(random.random(), random.random()) < 1:
    ...             count += 1
    ...     return count, size
    ... 
    >>> def process_samples(*sample_jobs):
    ...     count = 0 
    ...     size = 0
    ...     for j in sample_jobs:
    ...         count += j.result[0]
    ...         size += j.result[1]
    ...     return 4.0 * count / size
    ... 
    >>> class StubModule(object):
    ...     pass
    ...
    >>> pi = StubModule()
    >>> pi.generate_sample = generate_sample
    >>> pi.process_samples = process_samples

.. _`this one`: http://math.fullerton.edu/mathews/n2003/MonteCarloPiMod.html

--------------------------------
Our First Monte Carlo Experiment
--------------------------------

We'll need the ZEO server running.  If you've gone through this file from the
start, it should still be running.  If not, use this::

    $ ./bin/runzeo -a 9999 -f test.fs &

Now, for our first experiment with the Monte Carlo simulation, we'll start a
single worker process.

Enter this in the terminal::

    $ ./bin/python lib/python2.5/site-packages/pi.py &

That will start our worker process.  Now let's start an interpreter.

::

    $ ./bin/python

Now get a database and a connection, as we've seen before.  We'll also set up
the base zc.async configuration.

::

    >>  import ZEO.ClientStorage
    >>  import ZODB
    >>  storage = ZEO.ClientStorage.ClientStorage(
    ...     ('127.0.0.1', 9999))
    >>  db = ZODB.DB(storage)
    >>  conn = db.open()
    >>  import zc.async.configure
    >>  zc.async.configure.base()

We don't have any adapters installed, so ``zc.async.interfaces.IQueue(conn)``
won't work.  This will though, and still looks pretty good::

    >>> import zc.async.queue
    >>> q = zc.async.queue.getDefaultQueue(conn)

Now we can start some jobs in parallel.

::

    >>  import pi
    >>> import zc.async.job
    >>> j = q.put(zc.async.job.parallel(
    ...     pi.generate_sample, pi.generate_sample, pi.generate_sample,
    ...     postprocess=pi.process_samples))
    >>> import transaction
    >>> transaction.commit()

Wait a few seconds.  If the result is empty (None), begin the transaction again
and check the result again.  Eventually, these next two lines should give you a
similar result--an approximation of pi.

.. This lets us "wait a second".

    >>> zc.async.testing.wait_for_result(j) # doctest: +ELLIPSIS
    3.1...

..

::

    >>  _ = transaction.begin()
    >>  j.result
    3.1386666666666665

Cool.

--------
Closures
--------

Sometimes, you want to pass arguments to your functions.  In this case, what if
you want to pass a different ``size`` argument to ``generate_sample``?

You can always pass a Job directly to the queue (or to the ``parallel`` helper
function, in this case).  The job accepts arguments similarly to the Python 2.5
``functools.partial``: Job(func, \*args, \*\*keywords).  This instantiates a new
callable (a Job) with partial application of the given arguments and keywords.

Let's try it.

    >>> j = q.put(zc.async.job.parallel(
    ...     zc.async.job.Job(pi.generate_sample, 1000000),
    ...     zc.async.job.Job(pi.generate_sample, size=1000000),
    ...     postprocess=pi.process_samples))
    >>> transaction.commit()

Wait a bit, again.  Retry these two lines until you get a result.  It should
be well under a minute on most machines.

.. This lets us "wait a second".

    >>> zc.async.testing.wait_for_result(j, seconds=20) # doctest: +ELLIPSIS
    3.1...

..

::

    >>  _ = transaction.begin()
    >>  j.result
    3.1434359999999999

Cool.

-------------
Configuration
-------------

Unfortunately, the parallel runs we've done so far would actually make the
calculation go slower than if we did it in a single function call!  That's
because we ran it in a single Python worker process, and the overhead of
threads just makes the jobs a bit less efficient.  Threads help for some uses
of |async|, but not this one.

Let's assume you are running these experiments on a machine with two processor
cores.  We should actually start two worker processes then, one for each core.
We'll need to make sure each worker process has its own OID.

Moreover, we need to configure each process to only take one
``generate_sample`` job at a time.  Let's adjust our code to do that.

Agents
------

A worker process has a central polling activity, called a ``dispatcher``.
Dispatchers look in the database to ask their ``agent`` (or agents; think of it
as a "`talent agent`_" or a "booking agent") to determine what they should get
their threads to do.

By default using the zc.async.configure helpers, each dispatcher is given a
single agent that will choose the first job in the queue, and that wants to run
no more than three jobs at a time.

.. _`talent agent`: http://en.wikipedia.org/wiki/Talent_agent

XXX
===

Talk about callbacks, and how that lets you respond to results.

Talk briefly about failures, show the exceptions, and briefly mention logging
and debugging.

Start up multiple processes with dispatchers.

Close by referring to production instances needing something like zdaemon
or supervisor; and to preferring the more declarative zc.buildout style for
production...which we'll show in our next quickstart! ;-)

.. Now we are going to stop the reactor.

    >>> import zc.async.dispatcher
    >>> dispatcher = zc.async.dispatcher.get()
    >>> reactor = dispatcher.reactor
    >>> reactor.callFromThread(reactor.stop)
    >>> dispatcher.thread.join(3)
